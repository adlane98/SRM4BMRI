{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and test of MultiscaleSR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import SimpleITK as sitk\n",
    "from tensorflow import image, pad\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "from tensorflow.keras.layers import Add, Conv3D, Input, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from adamLRM import AdamLRM\n",
    "from patches import array_to_patches\n",
    "from store2hdf5 import store2hdf53D\n",
    "from utils3D import modcrop3D, shave3D, imadjust3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSNR calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def psnr_model(y_pred, y_true):\n",
    "    return image.psnr(y_pred.numpy(), y_true, np.max(y_pred.numpy())).numpy()\n",
    "\n",
    "def psnr(y_pred, y_true):\n",
    "    return image.psnr(y_pred, y_true, np.max(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def SRReCNN3D(input_shape, depth, nb_filters, kernel_size, padding, to_json=False):\n",
    "    input_layer = Input(input_shape)\n",
    "    layer = input_layer\n",
    "\n",
    "    for i in range(depth+1):\n",
    "        nf = 1 if i == depth else nb_filters\n",
    "        padded_layer = pad(layer, [[0, 0], [padding, padding], [padding, padding], [padding, padding], [0, 0]])\n",
    "        layer = Conv3D(\n",
    "            filters=nf,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=1,\n",
    "            padding=\"valid\",\n",
    "            kernel_initializer=RandomNormal(\n",
    "                mean=0,\n",
    "                stddev=np.sqrt(2.0/float(nb_filters * kernel_size ** 3))\n",
    "            ),\n",
    "            bias_initializer=Constant(0)\n",
    "        )(padded_layer)\n",
    "        if i < depth:\n",
    "            layer = ReLU()(layer)\n",
    "\n",
    "    final_layer = Add()([input_layer, layer])\n",
    "\n",
    "    #final_layer = Flatten()(final_layer)\n",
    "\n",
    "    model = Model(input_layer, final_layer)\n",
    "\n",
    "    if to_json:\n",
    "        with open(\"model.js\", \"w\") as json_model:\n",
    "            json_model.write(model.to_json())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NifTi Image and get numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_nifti = sitk.ReadImage(\"/projets/srm4bmri/originals/Marmoset_T1w_mri/1010.nii\")\n",
    "reference_image = sitk.GetArrayFromImage(reference_nifti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing to have a label and a low resolution image\n",
    "\n",
    "`reference_image` is a \"perfect\" image. Before running the model we need to artificially degrade it.\n",
    "\n",
    "### Definition of preprocessing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_sigma = 1\n",
    "downsampling_scale = (2, 2, 2)\n",
    "shaving_border = (0, 0, 0)\n",
    "interpolation_order = 3\n",
    "patch_size = 21\n",
    "patch_stride = 10\n",
    "max_number_patches = 3200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swap axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image = np.swapaxes(reference_image, 0, 2).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation and modcrop\n",
    "\n",
    "Modcrop is the function that makes the size of each dimension strictly proportional to the scale.\n",
    "\n",
    "If a dimension contains 80 values and the corresponding scale is equal to 3, then the resulting dimension size is 78 : `80 - 80 % 3 = 78`.\n",
    "\n",
    "This is done for having a perfect downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image = imadjust3D(reference_image, [0, 1])\n",
    "reference_image = modcrop3D(reference_image, downsampling_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blur and downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_reference_image = gaussian_filter(reference_image, sigma=blur_sigma)\n",
    "low_resolution_image = zoom(\n",
    "    blur_reference_image,\n",
    "    zoom=(1 / float(idxScale) for idxScale in downsampling_scale),\n",
    "    order=interpolation_order\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_image = zoom(\n",
    "    low_resolution_image, \n",
    "    zoom = downsampling_scale,\n",
    "    order = interpolation_order\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shaving\n",
    "\n",
    "At the edges of the images sometimes there are only black voxels. We need to remove them to make the model not training on that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_image = shave3D(reference_image, shaving_border)\n",
    "data_image = shave3D(interpolated_image, shaving_border)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract 3D patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 patches have been extracted\n",
      "270 patches have been extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/srm4bmri/aladjal/envs/test_venv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function extract_patches is deprecated; The function feature_extraction.image.extract_patches has been deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data_patches = array_to_patches(\n",
    "    data_image,\n",
    "    patch_shape = (patch_size, patch_size, patch_size),\n",
    "    extraction_step = patch_stride,\n",
    "    normalization = False\n",
    ")\n",
    "\n",
    "labels_patches = array_to_patches(\n",
    "    label_image,\n",
    "    patch_shape = (patch_size, patch_size, patch_size),\n",
    "    extraction_step = patch_stride,\n",
    "    normalization = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add channel axis !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_patches = data_patches[:, :, :, :, np.newaxis]\n",
    "labels_patches = labels_patches[:, :, :, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly rearrange and get the first `max_number_patches`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # makes the random numbers predictable\n",
    "random_order = np.random.permutation(data_patches.shape[0])\n",
    "\n",
    "data_patches = data_patches[random_order, :, :, :, :]\n",
    "labels_patches = labels_patches[random_order, :, :, :, :]\n",
    "\n",
    "# data_patches = data_patches[:max_number_patches, :, :, :, :]\n",
    "# labels_patches = labels_patches[:max_number_patches, :, :, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_depth = 10\n",
    "nb_filters = 64\n",
    "kernel_size = 3\n",
    "conv_padding = 1\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "adam_learning_rate = 0.0001\n",
    "residual_learning = False # Unused for the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and launch the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_training(\n",
    "    data,\n",
    "    labels, \n",
    "    depth = 10, \n",
    "    nb_filters = 64,\n",
    "    kernel_size = 3,\n",
    "    padding = 1,\n",
    "    epochs = 20,\n",
    "    batch_size = 4, \n",
    "    adam_lr = 0.0001\n",
    "):\n",
    "    model = SRReCNN3D(data[0].shape, depth, nb_filters, kernel_size, padding)\n",
    "    model.compile(\n",
    "        optimizer=AdamLRM(learning_rate=adam_lr), \n",
    "        loss=\"mse\", \n",
    "        metrics=[psnr_model],\n",
    "        run_eagerly=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "        data, \n",
    "        labels, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for drawing the loss and the PSNR metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_loss_and_psnr(history):\n",
    "    plt.figure(figsize=(11, 3))\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.epoch, history.history['loss'])\n",
    "    plt.title('loss')\n",
    "\n",
    "    # Plot PSNR metric\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.epoch, history.history['psnr_model'])\n",
    "    plt.title('psnr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 169s 34s/step - loss: 0.0011 - psnr_model: 29.5969\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 164s 33s/step - loss: 8.9457e-04 - psnr_model: 30.3226\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 166s 33s/step - loss: 8.7611e-04 - psnr_model: 30.7941\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 166s 33s/step - loss: 8.6585e-04 - psnr_model: 31.5106\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 166s 33s/step - loss: 8.5505e-04 - psnr_model: 30.6894\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 163s 33s/step - loss: 8.3970e-04 - psnr_model: 31.4453\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 164s 33s/step - loss: 8.2210e-04 - psnr_model: 30.8413\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 166s 33s/step - loss: 8.0400e-04 - psnr_model: 31.5699\n",
      "Epoch 9/10\n",
      "3/5 [=================>............] - ETA: 1:08 - loss: 7.8340e-04 - psnr_model: 30.6527"
     ]
    }
   ],
   "source": [
    "model, history =  launch_training(\n",
    "    data_patches,\n",
    "    labels_patches, \n",
    "    depth = network_depth, \n",
    "    nb_filters = nb_filters,\n",
    "    kernel_size = kernel_size,\n",
    "    padding = conv_padding,\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size, \n",
    "    adam_lr = adam_learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving weights: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from\n",
    "model.save_weights(\"/projets/srm4bmri/weights/mulstiscaleSR_training.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image = model.predict(interpolated_image[np.newaxis, :,:,:,np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk_image = sitk.GetImageFromArray(predicted_image[0, :, :, :, 0])\n",
    "sitk.WriteImage(sitk_image, \"/projets/srm4bmri/outputs/output_multiscale_sr.nii\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk_image = sitk.GetImageFromArray(interpolated_image)\n",
    "sitk.WriteImage(sitk_image, \"/projets/srm4bmri/outputs/input_multiscale_sr.nii\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}